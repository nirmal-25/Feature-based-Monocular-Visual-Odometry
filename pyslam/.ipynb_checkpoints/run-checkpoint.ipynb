{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decent-exercise",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "packed-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m WARNING: cannot import GeodescFeature2D from feature_geodesc, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import DelfFeature2D from feature_delf, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import ContextDescFeature2D from feature_contextdesc, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import LfNetFeature2D from feature_lfnet, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import KeyNetDescFeature2D from feature_keynet, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "from config import Config\n",
    "\n",
    "from visual_odometry import VisualOdometry\n",
    "from camera  import PinholeCamera\n",
    "from ground_truth import groundtruth_factory\n",
    "from dataset import dataset_factory\n",
    "\n",
    "#from mplot3d import Mplot3d\n",
    "#from mplot2d import Mplot2d\n",
    "from mplot_thread import Mplot2d, Mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from feature_tracker import feature_tracker_factory, FeatureTrackerTypes \n",
    "from feature_manager import feature_manager_factory\n",
    "from feature_types import FeatureDetectorTypes, FeatureDescriptorTypes, FeatureInfo\n",
    "from feature_matcher import feature_matcher_factory, FeatureMatcherTypes\n",
    "from tqdm import tqdm\n",
    "from feature_tracker_configs import FeatureTrackerConfigs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-contents",
   "metadata": {},
   "source": [
    "## Visual Odometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "narrative-lloyd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1101 [00:00<01:10, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Video Input\n",
      "num frames:  1101\n",
      "fps:  10.0\n",
      "using groundtruth:  video\n",
      "\u001b[33m WARNING: cannot import SIFT_create from cv2.xfeatures2d, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import SURF_create from cv2.xfeatures2d, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import FREAK_create from cv2.xfeatures2d, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import xfeatures2d_BoostDesc.create from cv2, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import xfeatures2d_MSDDetector from cv2, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import xfeatures2d_DAISY.create from cv2, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import xfeatures2d_StarDetector.create from cv2, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import xfeatures2d_HarrisLaplaceFeatureDetector.create from cv2, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import xfeatures2d_LATCH.create from cv2, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import xfeatures2d_LUCID.create from cv2, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import xfeatures2d_VGG.create from cv2, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import xfeatures2d.BEBLID_create from cv2, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: using NON-ORIENTED features:  FAST - NONE  (i.e. kp.angle=0)\n",
      "\u001b[0m\u001b[32m LkFeatureTracker: num levels on LK pyr optic flow:  3\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1101/1101 [02:11<00:00,  8.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# todo: add a loop for iterating over the kitti validation dataset\n",
    "config = Config()\n",
    "# todo: add input for kitti validation set\n",
    "dataset = dataset_factory(config.dataset_settings)\n",
    "groundtruth = groundtruth_factory(config.dataset_settings)\n",
    "\n",
    "cam = PinholeCamera(config.cam_settings['Camera.width'], config.cam_settings['Camera.height'],\n",
    "                    config.cam_settings['Camera.fx'], config.cam_settings['Camera.fy'],\n",
    "                    config.cam_settings['Camera.cx'], config.cam_settings['Camera.cy'],\n",
    "                    config.DistCoef, config.cam_settings['Camera.fps'])\n",
    "\n",
    "num_features=2000  # how many features do you want to detect and track?\n",
    "\n",
    "# select your tracker configuration (see the file feature_tracker_configs.py) \n",
    "# LK_SHI_TOMASI, LK_FAST\n",
    "# SHI_TOMASI_ORB, FAST_ORB, ORB, BRISK, AKAZE, FAST_FREAK, SIFT, ROOT_SIFT, SURF, SUPERPOINT, FAST_TFEAT\n",
    "tracker_config = FeatureTrackerConfigs.LK_FAST\n",
    "tracker_config['num_features'] = num_features\n",
    "\n",
    "feature_tracker = feature_tracker_factory(**tracker_config)\n",
    "\n",
    "# create visual odometry object \n",
    "vo = VisualOdometry(cam, groundtruth, feature_tracker)\n",
    "\n",
    "# todo: add the trajectory visualization\n",
    "traj_img_size = 800\n",
    "traj_img = np.zeros((traj_img_size, traj_img_size, 3), dtype=np.uint8)\n",
    "half_traj_img_size = int(0.5*traj_img_size)\n",
    "draw_scale = 1\n",
    "\n",
    "# second loop for iterating over all the frame\n",
    "err_x = []\n",
    "err_y = []\n",
    "err_z = []    \n",
    "for img_id in tqdm(range(dataset.num_frames)):\n",
    "    img = dataset.getImage(img_id)\n",
    "    if img is not None:\n",
    "        vo.track(img, img_id)\n",
    "#         break\n",
    "        if(img_id > 2):\n",
    "            x, y, z = vo.traj3d_est[-1]\n",
    "            x_true, y_true, z_true = vo.traj3d_gt[-1]\n",
    "            # calculate the error for x, y and z \n",
    "            err_x.append([img_id, math.fabs(x_true-x)])\n",
    "            err_y.append([img_id, math.fabs(y_true-y)])\n",
    "            err_z.append([img_id, math.fabs(z_true-z)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_x = np.array(err_x)\n",
    "err_y = np.array(err_y)\n",
    "err_z = np.array(err_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(err_x[:,0], err_x[:,1])\n",
    "plt.plot(err_y[:,0], err_y[:,1])\n",
    "plt.plot(err_z[:,0], err_z[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-marker",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: add a loop for iterating over the kitti validation dataset\n",
    "config = Config()\n",
    "# todo: add input for kitti validation set\n",
    "dataset = dataset_factory(config.dataset_settings)\n",
    "groundtruth = groundtruth_factory(config.dataset_settings)\n",
    "\n",
    "cam = PinholeCamera(config.cam_settings['Camera.width'], config.cam_settings['Camera.height'],\n",
    "                    config.cam_settings['Camera.fx'], config.cam_settings['Camera.fy'],\n",
    "                    config.cam_settings['Camera.cx'], config.cam_settings['Camera.cy'],\n",
    "                    config.DistCoef, config.cam_settings['Camera.fps'])\n",
    "\n",
    "num_features=2000  # how many features do you want to detect and track?\n",
    "\n",
    "# select your tracker configuration (see the file feature_tracker_configs.py) \n",
    "# LK_SHI_TOMASI, LK_FAST\n",
    "# SHI_TOMASI_ORB, FAST_ORB, ORB, BRISK, AKAZE, FAST_FREAK, SIFT, ROOT_SIFT, SURF, SUPERPOINT, FAST_TFEAT\n",
    "tracker_config = FeatureTrackerConfigs.LK_SHI_TOMASI\n",
    "tracker_config['num_features'] = num_features\n",
    "\n",
    "feature_tracker = feature_tracker_factory(**tracker_config)\n",
    "\n",
    "# create visual odometry object \n",
    "vo = VisualOdometry(cam, groundtruth, feature_tracker)\n",
    "\n",
    "# todo: add the trajectory visualization\n",
    "traj_img_size = 800\n",
    "traj_img = np.zeros((traj_img_size, traj_img_size, 3), dtype=np.uint8)\n",
    "half_traj_img_size = int(0.5*traj_img_size)\n",
    "draw_scale = 1\n",
    "\n",
    "\n",
    "\n",
    "img_id = 0\n",
    "err_x = []\n",
    "err_y = []\n",
    "err_z = []\n",
    "while dataset.isOk():\n",
    "    img = dataset.getImage(img_id)\n",
    "    if img is not None:\n",
    "        vo.track(img, img_id)  # main VO function \n",
    "        if(img_id > 2):\t       # start drawing from the third image (when everything is initialized and flows in a normal way)\n",
    "            err_x.append([img_id, math.fabs(x_true-x)])\n",
    "            err_y.append([img_id, math.fabs(y_true-y)])\n",
    "            err_z.append([img_id, math.fabs(z_true-z)])\n",
    "#             x, y, z = vo.traj3d_est[-1]\n",
    "#             x_true, y_true, z_true = vo.traj3d_gt[-1]\n",
    "\n",
    "#             if is_draw_traj_img:      # draw 2D trajectory (on the plane xz)\n",
    "#                 draw_x, draw_y = int(draw_scale*x) + half_traj_img_size, half_traj_img_size - int(draw_scale*z)\n",
    "#                 true_x, true_y = int(draw_scale*x_true) + half_traj_img_size, half_traj_img_size - int(draw_scale*z_true)\n",
    "#                 cv2.circle(traj_img, (draw_x, draw_y), 1,(img_id*255/4540, 255-img_id*255/4540, 0), 1)   # estimated from green to blue\n",
    "#                 cv2.circle(traj_img, (true_x, true_y), 1,(0, 0, 255), 1)  # groundtruth in red\n",
    "#                 # write text on traj_img\n",
    "#                 cv2.rectangle(traj_img, (10, 20), (600, 60), (0, 0, 0), -1)\n",
    "#                 text = \"Coordinates: x=%2fm y=%2fm z=%2fm\" % (x, y, z)\n",
    "#                 cv2.putText(traj_img, text, (20, 40), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1, 8)\n",
    "#                 # show \t\t\n",
    "#                 cv2.imshow('Trajectory', traj_img)\n",
    "\n",
    "#             if is_draw_3d:           # draw 3d trajectory \n",
    "#                 if kUsePangolin:\n",
    "#                     viewer3D.draw_vo(vo)   \n",
    "#                 else:\n",
    "#                     plt3d.drawTraj(vo.traj3d_gt,'ground truth',color='r',marker='.')\n",
    "#                     plt3d.drawTraj(vo.traj3d_est,'estimated',color='g',marker='.')\n",
    "#                     plt3d.refresh()\n",
    "\n",
    "#             if is_draw_err:         # draw error signals \n",
    "#                 errx = [img_id, math.fabs(x_true-x)]\n",
    "#                 erry = [img_id, math.fabs(y_true-y)]\n",
    "#                 errz = [img_id, math.fabs(z_true-z)] \n",
    "#                 err_plt.draw(errx,'err_x',color='g')\n",
    "#                 err_plt.draw(erry,'err_y',color='b')\n",
    "#                 err_plt.draw(errz,'err_z',color='r')\n",
    "#                 err_plt.refresh()    \n",
    "\n",
    "#             if is_draw_matched_points:\n",
    "#                 matched_kps_signal = [img_id, vo.num_matched_kps]\n",
    "#                 inliers_signal = [img_id, vo.num_inliers]                    \n",
    "#                 matched_points_plt.draw(matched_kps_signal,'# matches',color='b')\n",
    "#                 matched_points_plt.draw(inliers_signal,'# inliers',color='g')                    \n",
    "#                 matched_points_plt.refresh()                    \n",
    "\n",
    "\n",
    "#         # draw camera image \n",
    "#         cv2.imshow('Camera', vo.draw_img)\t\t\t\t\n",
    "\n",
    "#     # press 'q' to exit!\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "    img_id += 1\n",
    "\n",
    "#print('press a key in order to exit...')\n",
    "# #cv2.waitKey(0)\n",
    "\n",
    "# if is_draw_traj_img:\n",
    "#     print('saving map.png')\n",
    "#     cv2.imwrite('map.png', traj_img)\n",
    "# if is_draw_3d:\n",
    "#     if not kUsePangolin:\n",
    "#         plt3d.quit()\n",
    "#     else: \n",
    "#         viewer3D.quit()\n",
    "# if is_draw_err:\n",
    "#     err_plt.quit()\n",
    "# if is_draw_matched_points is not None:\n",
    "#     matched_points_plt.quit()\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-nelson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyslam",
   "language": "python",
   "name": "pyslam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
